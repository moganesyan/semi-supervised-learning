{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(str(Path(\"../../ssl\").resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.pi_model.pi_model import PiModel\n",
    "from src.models.pi_model.pi_model_config import PiModelConfig\n",
    "from src.trainers.pi_model_alt.pi_model import PiModelTrainer\n",
    "from src.trainers.pi_model_alt.pi_model_config import PiModelTrainerConfig\n",
    "from src.data_loaders.pi_model_alt.pi_model_config import PiModelDataLoaderConfig\n",
    "from src.data_loaders.pi_model_alt.pi_model import PiModelDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "In this notebook, the AlexNet model will be trained on the CIFAR-10 dataset using only 25% of the labelled dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainerConfig(PiModelTrainerConfig):\n",
    "    num_epochs = 150\n",
    "    loss_ramp_up_epochs = 100\n",
    "    unsup_loss_weight = 5.0\n",
    "\n",
    "train_config = TrainerConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConfig(PiModelConfig):\n",
    "    input_shape = (32, 32, 3)\n",
    "    output_shape = 10\n",
    "\n",
    "model_config = ModelConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderConfig(PiModelDataLoaderConfig):\n",
    "    batch_size = 64\n",
    "    num_classes = 10\n",
    "\n",
    "    blur_params = {\n",
    "        'chance': 0.10,\n",
    "        'kernel_ratio': 0.10,\n",
    "        'blur_strength': (0.1, 2.0)\n",
    "    }\n",
    "\n",
    "    crop_params = {\n",
    "        'chance': 0.50,\n",
    "        'crop_size': (0.08, 1.0),\n",
    "        'aspect_range': (0.75, 1.33),\n",
    "        'num_tries': 100\n",
    "    }\n",
    "\n",
    "    jitter_params = {\n",
    "        'chance': 0.50,\n",
    "        'distort_strength': 0.20,\n",
    "        'drop_chance': 0.05\n",
    "    }\n",
    "\n",
    "data_loader_config = DataLoaderConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test_full, y_test_full) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train dataset by subsampling 10% of the full training dataset (stratified by labels)\n",
    "# add the rest as unlabelled samples\n",
    "x_train_unlabelled, x_train_labelled, y_train_unlabelled_, y_train_labelled = train_test_split(\n",
    "    x_train_full, y_train_full,\n",
    "    stratify = y_train_full,\n",
    "    test_size = 0.20, random_state = 42\n",
    ")\n",
    "y_train_unlabelled = (-1 * np.ones_like(y_train_unlabelled_)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((x_train_unlabelled, x_train_labelled), axis = 0)\n",
    "y_train = np.concatenate((y_train_unlabelled, y_train_labelled), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = shuffle(x_train, y_train, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_unlabelled = tf.data.Dataset.from_tensor_slices((x_train_unlabelled, y_train_unlabelled))\n",
    "# train_data_labelled = tf.data.Dataset.from_tensor_slices((x_train_labelled, y_train_labelled))\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_test_full, y_test_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train dataset\n",
    "train_data = PiModelDataLoader(train_data, data_loader_config)(training = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test dataset\n",
    "val_data = PiModelDataLoader(val_data, data_loader_config)(training = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train dataset size: {train_data.cardinality()}\")\n",
    "print(f\"Validation dataset size: {val_data.cardinality()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (x1,x2,x3,x4,y) in train_data.take(1):\n",
    "#     print(x1, x2, x3, x4, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PiModel(model_config)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PiModelTrainer(\n",
    "    model, train_data, train_config,\n",
    "    val_dataset = val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0dadcd243d7a81fb679ed94fa0b3507371cb4f0217aac2cbcd3d9c4ad08fe2a2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

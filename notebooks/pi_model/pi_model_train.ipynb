{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-13 16:28:45.573758: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-13 16:28:45.709487: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-13 16:28:46.166421: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.4/lib64\n",
      "2022-11-13 16:28:46.166479: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.4/lib64\n",
      "2022-11-13 16:28:46.166491: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikheil/.conda/envs/ssl-repo/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(str(Path(\"../../ssl\").resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.pi_model.pi_model import PiModel\n",
    "from src.models.pi_model.pi_model_config import PiModelConfig\n",
    "from src.trainers.pi_model.pi_model import PiModelTrainer\n",
    "from src.trainers.pi_model.pi_model_config import PiModelTrainerConfig\n",
    "from src.data_loaders.pi_model.pi_model_config import PiModelDataLoaderConfig\n",
    "from src.data_loaders.pi_model.pi_model import PiModelDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "In this notebook, the AlexNet model will be trained on the CIFAR-10 dataset using only 25% of the labelled dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainerConfig(PiModelTrainerConfig):\n",
    "    num_epochs = 200\n",
    "    loss_ramp_up_epochs = 150\n",
    "    unsup_loss_weight = 3.0\n",
    "\n",
    "train_config = TrainerConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConfig(PiModelConfig):\n",
    "    input_shape = (32, 32, 3)\n",
    "    output_shape = 10\n",
    "\n",
    "model_config = ModelConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderConfig(PiModelDataLoaderConfig):\n",
    "    batch_size = 64\n",
    "    num_classes = 10\n",
    "    shuffle_buffer_size = 50000 # dataset size    \n",
    "\n",
    "    blur_params = {\n",
    "        'chance': 0.10,\n",
    "        'kernel_ratio': 0.10,\n",
    "        'blur_strength': (0.1, 2.0)\n",
    "    }\n",
    "\n",
    "    crop_params = {\n",
    "        'chance': 0.50,\n",
    "        'crop_size': (0.08, 1.0),\n",
    "        'aspect_range': (0.75, 1.33),\n",
    "        'num_tries': 100\n",
    "    }\n",
    "\n",
    "    jitter_params = {\n",
    "        'chance': 0.50,\n",
    "        'distort_strength': 0.20,\n",
    "        'drop_chance': 0.05\n",
    "    }\n",
    "\n",
    "data_loader_config = DataLoaderConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test_full, y_test_full) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train dataset by subsampling 10% of the full training dataset (stratified by labels)\n",
    "# add the rest as unlabelled samples\n",
    "x_train_unlabelled, x_train_labelled, y_train_unlabelled_, y_train_labelled = train_test_split(\n",
    "    x_train_full, y_train_full,\n",
    "    stratify = y_train_full,\n",
    "    test_size = 0.10, random_state = 42\n",
    ")\n",
    "\n",
    "# cast types\n",
    "y_train_unlabelled = (-1 * np.ones_like(y_train_unlabelled_)).astype(np.int64)\n",
    "y_train_labelled = y_train_labelled.astype(np.int64)\n",
    "y_test_full = y_test_full.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((x_train_unlabelled, x_train_labelled), axis = 0)\n",
    "y_train = np.concatenate((y_train_unlabelled, y_train_labelled), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-13 16:28:48.290954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-13 16:28:48.298679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-13 16:28:48.299366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-13 16:28:48.300530: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-13 16:28:48.301021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-13 16:28:48.301643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-13 16:28:48.302232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-13 16:28:48.740179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-13 16:28:48.740692: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-13 16:28:48.741148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-13 16:28:48.741569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6983 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_test_full, y_test_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train dataset\n",
    "train_data = PiModelDataLoader(train_data, data_loader_config)(training = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test dataset\n",
    "val_data = PiModelDataLoader(val_data, data_loader_config)(training = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 782\n",
      "Validation dataset size: 157\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset size: {train_data.cardinality()}\")\n",
    "print(f\"Validation dataset size: {val_data.cardinality()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PiModel(model_config)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PiModelTrainer(\n",
    "    model, train_data, train_config,\n",
    "    val_dataset = val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-13 16:28:51.608970: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 0 is : 2.26. Validation loss is : 2.13. Validation acc. is : 19.75.\n",
      "Training loss at epoch 1 is : 2.05. Validation loss is : 1.99. Validation acc. is : 26.60.\n",
      "Training loss at epoch 2 is : 1.96. Validation loss is : 1.86. Validation acc. is : 29.38.\n",
      "Training loss at epoch 3 is : 1.90. Validation loss is : 1.82. Validation acc. is : 33.21.\n",
      "Training loss at epoch 4 is : 1.86. Validation loss is : 1.74. Validation acc. is : 34.26.\n",
      "Training loss at epoch 5 is : 1.81. Validation loss is : 1.67. Validation acc. is : 36.56.\n",
      "Training loss at epoch 6 is : 1.77. Validation loss is : 1.64. Validation acc. is : 39.37.\n",
      "Training loss at epoch 7 is : 1.74. Validation loss is : 1.84. Validation acc. is : 35.09.\n",
      "Training loss at epoch 8 is : 1.69. Validation loss is : 1.60. Validation acc. is : 40.71.\n",
      "Training loss at epoch 9 is : 1.67. Validation loss is : 1.51. Validation acc. is : 44.84.\n",
      "Training loss at epoch 10 is : 1.65. Validation loss is : 1.54. Validation acc. is : 42.67.\n",
      "Training loss at epoch 11 is : 1.61. Validation loss is : 1.53. Validation acc. is : 44.87.\n",
      "Training loss at epoch 12 is : 1.61. Validation loss is : 1.58. Validation acc. is : 44.01.\n",
      "Training loss at epoch 13 is : 1.56. Validation loss is : 1.44. Validation acc. is : 46.99.\n",
      "Training loss at epoch 14 is : 1.53. Validation loss is : 1.45. Validation acc. is : 48.49.\n",
      "Training loss at epoch 15 is : 1.53. Validation loss is : 1.41. Validation acc. is : 48.86.\n",
      "Training loss at epoch 16 is : 1.45. Validation loss is : 1.36. Validation acc. is : 50.78.\n",
      "Training loss at epoch 17 is : 1.44. Validation loss is : 1.28. Validation acc. is : 53.66.\n",
      "Training loss at epoch 18 is : 1.42. Validation loss is : 1.37. Validation acc. is : 50.28.\n",
      "Training loss at epoch 19 is : 1.41. Validation loss is : 1.29. Validation acc. is : 53.22.\n",
      "Training loss at epoch 20 is : 1.37. Validation loss is : 1.43. Validation acc. is : 49.49.\n",
      "Training loss at epoch 21 is : 1.36. Validation loss is : 1.49. Validation acc. is : 47.04.\n",
      "Training loss at epoch 22 is : 1.35. Validation loss is : 1.22. Validation acc. is : 56.71.\n",
      "Training loss at epoch 23 is : 1.29. Validation loss is : 1.30. Validation acc. is : 53.70.\n",
      "Training loss at epoch 24 is : 1.29. Validation loss is : 1.25. Validation acc. is : 55.59.\n",
      "Training loss at epoch 25 is : 1.28. Validation loss is : 1.19. Validation acc. is : 57.24.\n",
      "Training loss at epoch 26 is : 1.23. Validation loss is : 1.20. Validation acc. is : 57.66.\n",
      "Training loss at epoch 27 is : 1.22. Validation loss is : 1.21. Validation acc. is : 57.06.\n",
      "Training loss at epoch 28 is : 1.19. Validation loss is : 1.20. Validation acc. is : 57.46.\n",
      "Training loss at epoch 29 is : 1.20. Validation loss is : 1.17. Validation acc. is : 58.73.\n",
      "Training loss at epoch 30 is : 1.14. Validation loss is : 1.13. Validation acc. is : 59.93.\n",
      "Training loss at epoch 31 is : 1.12. Validation loss is : 1.15. Validation acc. is : 60.87.\n",
      "Training loss at epoch 32 is : 1.11. Validation loss is : 1.20. Validation acc. is : 59.53.\n",
      "Training loss at epoch 33 is : 1.13. Validation loss is : 1.11. Validation acc. is : 60.87.\n",
      "Training loss at epoch 34 is : 1.08. Validation loss is : 1.18. Validation acc. is : 60.48.\n",
      "Training loss at epoch 35 is : 1.05. Validation loss is : 1.20. Validation acc. is : 57.61.\n",
      "Training loss at epoch 36 is : 1.05. Validation loss is : 1.15. Validation acc. is : 61.36.\n",
      "Training loss at epoch 37 is : 1.01. Validation loss is : 1.12. Validation acc. is : 61.99.\n",
      "Training loss at epoch 38 is : 1.01. Validation loss is : 1.19. Validation acc. is : 61.11.\n",
      "Training loss at epoch 39 is : 0.99. Validation loss is : 1.19. Validation acc. is : 61.80.\n",
      "Training loss at epoch 40 is : 1.01. Validation loss is : 1.13. Validation acc. is : 62.87.\n",
      "Training loss at epoch 41 is : 0.97. Validation loss is : 1.10. Validation acc. is : 64.12.\n",
      "Training loss at epoch 42 is : 0.97. Validation loss is : 1.14. Validation acc. is : 63.37.\n",
      "Training loss at epoch 43 is : 0.94. Validation loss is : 1.08. Validation acc. is : 64.24.\n",
      "Training loss at epoch 44 is : 0.92. Validation loss is : 1.45. Validation acc. is : 56.80.\n",
      "Training loss at epoch 45 is : 0.88. Validation loss is : 1.16. Validation acc. is : 64.28.\n",
      "Training loss at epoch 46 is : 0.89. Validation loss is : 1.19. Validation acc. is : 62.17.\n",
      "Training loss at epoch 47 is : 0.88. Validation loss is : 1.36. Validation acc. is : 59.12.\n",
      "Training loss at epoch 48 is : 0.87. Validation loss is : 1.15. Validation acc. is : 64.20.\n",
      "Training loss at epoch 49 is : 0.84. Validation loss is : 1.05. Validation acc. is : 65.98.\n",
      "Training loss at epoch 50 is : 0.81. Validation loss is : 1.19. Validation acc. is : 64.39.\n",
      "Training loss at epoch 51 is : 0.81. Validation loss is : 1.06. Validation acc. is : 66.41.\n",
      "Training loss at epoch 52 is : 0.81. Validation loss is : 1.11. Validation acc. is : 64.94.\n",
      "Training loss at epoch 53 is : 0.78. Validation loss is : 1.08. Validation acc. is : 65.94.\n",
      "Training loss at epoch 54 is : 0.79. Validation loss is : 1.10. Validation acc. is : 65.81.\n",
      "Training loss at epoch 55 is : 0.75. Validation loss is : 1.08. Validation acc. is : 66.77.\n",
      "Training loss at epoch 56 is : 0.79. Validation loss is : 1.09. Validation acc. is : 66.72.\n",
      "Training loss at epoch 57 is : 0.77. Validation loss is : 1.17. Validation acc. is : 66.13.\n",
      "Training loss at epoch 58 is : 0.75. Validation loss is : 1.14. Validation acc. is : 65.86.\n",
      "Training loss at epoch 59 is : 0.74. Validation loss is : 1.08. Validation acc. is : 67.53.\n",
      "Training loss at epoch 60 is : 0.73. Validation loss is : 1.12. Validation acc. is : 65.67.\n",
      "Training loss at epoch 61 is : 0.75. Validation loss is : 1.15. Validation acc. is : 65.78.\n",
      "Training loss at epoch 62 is : 0.74. Validation loss is : 1.08. Validation acc. is : 66.36.\n",
      "Training loss at epoch 63 is : 0.74. Validation loss is : 1.10. Validation acc. is : 66.59.\n",
      "Training loss at epoch 64 is : 0.73. Validation loss is : 1.09. Validation acc. is : 66.35.\n",
      "Training loss at epoch 65 is : 0.72. Validation loss is : 1.03. Validation acc. is : 68.10.\n",
      "Training loss at epoch 66 is : 0.71. Validation loss is : 1.13. Validation acc. is : 65.73.\n",
      "Training loss at epoch 67 is : 0.73. Validation loss is : 1.10. Validation acc. is : 66.02.\n",
      "Training loss at epoch 68 is : 0.72. Validation loss is : 0.99. Validation acc. is : 69.07.\n",
      "Training loss at epoch 69 is : 0.68. Validation loss is : 1.06. Validation acc. is : 68.72.\n",
      "Training loss at epoch 70 is : 0.70. Validation loss is : 1.17. Validation acc. is : 65.54.\n",
      "Training loss at epoch 71 is : 0.68. Validation loss is : 1.06. Validation acc. is : 67.43.\n",
      "Training loss at epoch 72 is : 0.69. Validation loss is : 1.01. Validation acc. is : 67.59.\n",
      "Training loss at epoch 73 is : 0.70. Validation loss is : 1.01. Validation acc. is : 68.35.\n",
      "Training loss at epoch 74 is : 0.70. Validation loss is : 1.07. Validation acc. is : 67.78.\n",
      "Training loss at epoch 75 is : 0.69. Validation loss is : 1.02. Validation acc. is : 67.38.\n",
      "Training loss at epoch 76 is : 0.69. Validation loss is : 0.99. Validation acc. is : 68.59.\n",
      "Training loss at epoch 77 is : 0.69. Validation loss is : 0.99. Validation acc. is : 68.82.\n",
      "Training loss at epoch 78 is : 0.68. Validation loss is : 1.01. Validation acc. is : 68.39.\n",
      "Training loss at epoch 79 is : 0.69. Validation loss is : 0.96. Validation acc. is : 69.57.\n",
      "Training loss at epoch 80 is : 0.69. Validation loss is : 0.99. Validation acc. is : 69.66.\n",
      "Training loss at epoch 81 is : 0.69. Validation loss is : 1.02. Validation acc. is : 68.96.\n",
      "Training loss at epoch 82 is : 0.70. Validation loss is : 0.93. Validation acc. is : 68.91.\n",
      "Training loss at epoch 83 is : 0.68. Validation loss is : 1.03. Validation acc. is : 67.85.\n",
      "Training loss at epoch 84 is : 0.69. Validation loss is : 1.03. Validation acc. is : 68.54.\n",
      "Training loss at epoch 85 is : 0.69. Validation loss is : 0.98. Validation acc. is : 68.93.\n",
      "Training loss at epoch 86 is : 0.67. Validation loss is : 0.95. Validation acc. is : 68.96.\n",
      "Training loss at epoch 87 is : 0.68. Validation loss is : 0.93. Validation acc. is : 69.36.\n",
      "Training loss at epoch 88 is : 0.68. Validation loss is : 0.94. Validation acc. is : 69.13.\n",
      "Training loss at epoch 89 is : 0.69. Validation loss is : 0.95. Validation acc. is : 68.93.\n",
      "Training loss at epoch 90 is : 0.66. Validation loss is : 0.96. Validation acc. is : 69.47.\n",
      "Training loss at epoch 91 is : 0.68. Validation loss is : 0.97. Validation acc. is : 68.25.\n",
      "Training loss at epoch 92 is : 0.66. Validation loss is : 0.88. Validation acc. is : 69.61.\n",
      "Training loss at epoch 93 is : 0.69. Validation loss is : 0.92. Validation acc. is : 69.14.\n",
      "Training loss at epoch 94 is : 0.70. Validation loss is : 1.03. Validation acc. is : 65.94.\n",
      "Training loss at epoch 95 is : 0.70. Validation loss is : 0.90. Validation acc. is : 69.60.\n",
      "Training loss at epoch 96 is : 0.69. Validation loss is : 0.92. Validation acc. is : 69.13.\n",
      "Training loss at epoch 97 is : 0.68. Validation loss is : 0.89. Validation acc. is : 69.80.\n",
      "Training loss at epoch 98 is : 0.67. Validation loss is : 0.95. Validation acc. is : 68.11.\n",
      "Training loss at epoch 99 is : 0.68. Validation loss is : 0.91. Validation acc. is : 69.02.\n",
      "Training loss at epoch 100 is : 0.66. Validation loss is : 0.84. Validation acc. is : 71.87.\n",
      "Training loss at epoch 101 is : 0.67. Validation loss is : 0.93. Validation acc. is : 69.21.\n",
      "Training loss at epoch 102 is : 0.67. Validation loss is : 0.87. Validation acc. is : 70.63.\n",
      "Training loss at epoch 103 is : 0.67. Validation loss is : 1.00. Validation acc. is : 66.09.\n",
      "Training loss at epoch 104 is : 0.70. Validation loss is : 0.91. Validation acc. is : 68.66.\n",
      "Training loss at epoch 105 is : 0.69. Validation loss is : 0.93. Validation acc. is : 69.42.\n",
      "Training loss at epoch 106 is : 0.67. Validation loss is : 0.88. Validation acc. is : 70.40.\n",
      "Training loss at epoch 107 is : 0.68. Validation loss is : 0.90. Validation acc. is : 69.46.\n",
      "Training loss at epoch 108 is : 0.66. Validation loss is : 0.87. Validation acc. is : 71.03.\n",
      "Training loss at epoch 109 is : 0.69. Validation loss is : 0.88. Validation acc. is : 69.86.\n",
      "Training loss at epoch 110 is : 0.68. Validation loss is : 0.95. Validation acc. is : 68.30.\n",
      "Training loss at epoch 111 is : 0.67. Validation loss is : 0.90. Validation acc. is : 69.44.\n",
      "Training loss at epoch 112 is : 0.69. Validation loss is : 0.92. Validation acc. is : 68.07.\n",
      "Training loss at epoch 113 is : 0.67. Validation loss is : 0.92. Validation acc. is : 68.89.\n",
      "Training loss at epoch 114 is : 0.67. Validation loss is : 0.95. Validation acc. is : 67.43.\n",
      "Training loss at epoch 115 is : 0.67. Validation loss is : 0.88. Validation acc. is : 70.08.\n",
      "Training loss at epoch 116 is : 0.67. Validation loss is : 0.86. Validation acc. is : 70.80.\n",
      "Training loss at epoch 117 is : 0.68. Validation loss is : 0.91. Validation acc. is : 69.41.\n",
      "Training loss at epoch 118 is : 0.69. Validation loss is : 0.91. Validation acc. is : 69.44.\n",
      "Training loss at epoch 119 is : 0.66. Validation loss is : 0.93. Validation acc. is : 67.92.\n",
      "Training loss at epoch 120 is : 0.67. Validation loss is : 0.89. Validation acc. is : 70.96.\n",
      "Training loss at epoch 121 is : 0.66. Validation loss is : 0.91. Validation acc. is : 69.06.\n",
      "Training loss at epoch 122 is : 0.66. Validation loss is : 0.87. Validation acc. is : 71.20.\n",
      "Training loss at epoch 123 is : 0.66. Validation loss is : 0.91. Validation acc. is : 69.06.\n",
      "Training loss at epoch 124 is : 0.66. Validation loss is : 0.88. Validation acc. is : 69.87.\n",
      "Training loss at epoch 125 is : 0.66. Validation loss is : 0.94. Validation acc. is : 68.11.\n",
      "Training loss at epoch 126 is : 0.66. Validation loss is : 0.94. Validation acc. is : 67.95.\n",
      "Training loss at epoch 127 is : 0.65. Validation loss is : 0.89. Validation acc. is : 70.67.\n",
      "Training loss at epoch 128 is : 0.64. Validation loss is : 0.94. Validation acc. is : 68.93.\n",
      "Training loss at epoch 129 is : 0.67. Validation loss is : 0.94. Validation acc. is : 69.46.\n",
      "Training loss at epoch 130 is : 0.65. Validation loss is : 0.92. Validation acc. is : 68.89.\n",
      "Training loss at epoch 131 is : 0.65. Validation loss is : 0.93. Validation acc. is : 69.22.\n",
      "Training loss at epoch 132 is : 0.65. Validation loss is : 0.91. Validation acc. is : 70.48.\n",
      "Training loss at epoch 133 is : 0.63. Validation loss is : 0.90. Validation acc. is : 70.06.\n",
      "Training loss at epoch 134 is : 0.65. Validation loss is : 0.95. Validation acc. is : 67.84.\n",
      "Training loss at epoch 135 is : 0.63. Validation loss is : 0.96. Validation acc. is : 68.89.\n",
      "Training loss at epoch 136 is : 0.63. Validation loss is : 0.91. Validation acc. is : 70.26.\n",
      "Training loss at epoch 137 is : 0.64. Validation loss is : 0.91. Validation acc. is : 70.90.\n",
      "Training loss at epoch 138 is : 0.62. Validation loss is : 0.94. Validation acc. is : 68.69.\n",
      "Training loss at epoch 139 is : 0.65. Validation loss is : 0.95. Validation acc. is : 70.12.\n",
      "Training loss at epoch 140 is : 0.63. Validation loss is : 0.92. Validation acc. is : 70.29.\n",
      "Training loss at epoch 141 is : 0.62. Validation loss is : 0.96. Validation acc. is : 67.70.\n",
      "Training loss at epoch 142 is : 0.60. Validation loss is : 1.01. Validation acc. is : 65.75.\n",
      "Training loss at epoch 143 is : 0.63. Validation loss is : 0.98. Validation acc. is : 68.44.\n",
      "Training loss at epoch 144 is : 0.62. Validation loss is : 0.98. Validation acc. is : 68.98.\n",
      "Training loss at epoch 145 is : 0.60. Validation loss is : 0.97. Validation acc. is : 68.05.\n",
      "Training loss at epoch 146 is : 0.60. Validation loss is : 0.98. Validation acc. is : 68.51.\n",
      "Training loss at epoch 147 is : 0.62. Validation loss is : 1.00. Validation acc. is : 68.58.\n",
      "Training loss at epoch 148 is : 0.59. Validation loss is : 0.98. Validation acc. is : 70.35.\n",
      "Training loss at epoch 149 is : 0.60. Validation loss is : 0.99. Validation acc. is : 67.92.\n",
      "Training loss at epoch 150 is : 0.62. Validation loss is : 0.98. Validation acc. is : 68.85.\n",
      "Training loss at epoch 151 is : 0.61. Validation loss is : 1.00. Validation acc. is : 67.50.\n",
      "Training loss at epoch 152 is : 0.58. Validation loss is : 0.96. Validation acc. is : 68.81.\n",
      "Training loss at epoch 153 is : 0.62. Validation loss is : 1.06. Validation acc. is : 67.54.\n",
      "Training loss at epoch 154 is : 0.60. Validation loss is : 1.04. Validation acc. is : 66.27.\n",
      "Training loss at epoch 155 is : 0.61. Validation loss is : 0.98. Validation acc. is : 68.67.\n",
      "Training loss at epoch 156 is : 0.57. Validation loss is : 1.00. Validation acc. is : 68.71.\n",
      "Training loss at epoch 157 is : 0.58. Validation loss is : 0.97. Validation acc. is : 69.81.\n",
      "Training loss at epoch 158 is : 0.56. Validation loss is : 0.96. Validation acc. is : 69.29.\n",
      "Training loss at epoch 159 is : 0.56. Validation loss is : 1.02. Validation acc. is : 67.10.\n",
      "Training loss at epoch 160 is : 0.57. Validation loss is : 1.01. Validation acc. is : 69.10.\n",
      "Training loss at epoch 161 is : 0.57. Validation loss is : 1.04. Validation acc. is : 67.50.\n",
      "Training loss at epoch 162 is : 0.56. Validation loss is : 1.02. Validation acc. is : 68.79.\n",
      "Training loss at epoch 163 is : 0.57. Validation loss is : 0.98. Validation acc. is : 67.69.\n",
      "Training loss at epoch 164 is : 0.56. Validation loss is : 0.98. Validation acc. is : 68.94.\n",
      "Training loss at epoch 165 is : 0.57. Validation loss is : 0.98. Validation acc. is : 68.89.\n",
      "Training loss at epoch 166 is : 0.53. Validation loss is : 1.01. Validation acc. is : 67.08.\n",
      "Training loss at epoch 167 is : 0.55. Validation loss is : 1.07. Validation acc. is : 66.14.\n",
      "Training loss at epoch 168 is : 0.54. Validation loss is : 1.01. Validation acc. is : 69.21.\n",
      "Training loss at epoch 169 is : 0.54. Validation loss is : 1.03. Validation acc. is : 67.98.\n",
      "Training loss at epoch 170 is : 0.55. Validation loss is : 1.03. Validation acc. is : 66.80.\n",
      "Training loss at epoch 171 is : 0.55. Validation loss is : 0.99. Validation acc. is : 68.98.\n",
      "Training loss at epoch 172 is : 0.55. Validation loss is : 1.02. Validation acc. is : 67.75.\n",
      "Training loss at epoch 173 is : 0.53. Validation loss is : 1.02. Validation acc. is : 67.69.\n",
      "Training loss at epoch 174 is : 0.54. Validation loss is : 1.02. Validation acc. is : 68.70.\n",
      "Training loss at epoch 175 is : 0.56. Validation loss is : 1.07. Validation acc. is : 68.31.\n",
      "Training loss at epoch 176 is : 0.52. Validation loss is : 1.00. Validation acc. is : 69.50.\n",
      "Training loss at epoch 177 is : 0.51. Validation loss is : 1.03. Validation acc. is : 68.00.\n",
      "Training loss at epoch 178 is : 0.53. Validation loss is : 1.05. Validation acc. is : 68.76.\n",
      "Training loss at epoch 179 is : 0.55. Validation loss is : 1.07. Validation acc. is : 68.30.\n",
      "Training loss at epoch 180 is : 0.51. Validation loss is : 1.05. Validation acc. is : 68.09.\n",
      "Training loss at epoch 181 is : 0.52. Validation loss is : 1.02. Validation acc. is : 68.21.\n",
      "Training loss at epoch 182 is : 0.52. Validation loss is : 1.11. Validation acc. is : 68.65.\n",
      "Training loss at epoch 183 is : 0.51. Validation loss is : 1.11. Validation acc. is : 66.67.\n",
      "Training loss at epoch 184 is : 0.50. Validation loss is : 1.05. Validation acc. is : 69.37.\n",
      "Training loss at epoch 185 is : 0.52. Validation loss is : 1.05. Validation acc. is : 67.92.\n",
      "Training loss at epoch 186 is : 0.50. Validation loss is : 1.06. Validation acc. is : 67.99.\n",
      "Training loss at epoch 187 is : 0.51. Validation loss is : 1.05. Validation acc. is : 67.20.\n",
      "Training loss at epoch 188 is : 0.50. Validation loss is : 1.07. Validation acc. is : 65.53.\n",
      "Training loss at epoch 189 is : 0.52. Validation loss is : 0.99. Validation acc. is : 67.96.\n",
      "Training loss at epoch 190 is : 0.51. Validation loss is : 1.15. Validation acc. is : 65.77.\n",
      "Training loss at epoch 191 is : 0.53. Validation loss is : 1.14. Validation acc. is : 65.47.\n",
      "Training loss at epoch 192 is : 0.48. Validation loss is : 1.01. Validation acc. is : 68.11.\n",
      "Training loss at epoch 193 is : 0.49. Validation loss is : 1.07. Validation acc. is : 66.51.\n",
      "Training loss at epoch 194 is : 0.50. Validation loss is : 1.08. Validation acc. is : 67.62.\n",
      "Training loss at epoch 195 is : 0.48. Validation loss is : 1.08. Validation acc. is : 67.72.\n",
      "Training loss at epoch 196 is : 0.48. Validation loss is : 1.11. Validation acc. is : 68.30.\n",
      "Training loss at epoch 197 is : 0.49. Validation loss is : 1.10. Validation acc. is : 67.87.\n",
      "Training loss at epoch 198 is : 0.49. Validation loss is : 1.14. Validation acc. is : 67.70.\n",
      "Training loss at epoch 199 is : 0.49. Validation loss is : 1.11. Validation acc. is : 65.86.\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0dadcd243d7a81fb679ed94fa0b3507371cb4f0217aac2cbcd3d9c4ad08fe2a2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
